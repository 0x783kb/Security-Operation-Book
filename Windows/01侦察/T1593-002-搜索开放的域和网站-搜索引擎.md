# T1593-002-搜索开放的域和网站-搜索引擎

## 描述
攻击者在入侵目标组织之前，可能通过搜索引擎收集目标的网络信息。搜索引擎（如Google、Bing、百度）通过爬取在线站点并索引内容，提供丰富的公开信息。攻击者可利用专门的搜索语法（如Google Hacking）查询目标的敏感信息，例如子域名、泄露的凭据、配置文件、后台地址或网络设备信息。这些信息可帮助攻击者了解目标的网络架构、关键资产或潜在漏洞。

攻击者可能通过以下方式使用搜索引擎：
- **Google Hacking**：使用高级搜索语法（如`intitle`、`inurl`）查找目标网站的敏感页面或文件。
- **公开信息搜刮**：搜索与目标相关的公开文档、员工信息或业务关系。
- **社会工程结合**：利用搜索到的邮箱或联系信息发起针对性钓鱼攻击。
- **泄露数据挖掘**：查找Pastebin或其他平台上泄露的与目标相关的敏感信息。

收集到的信息可能为后续攻击活动做准备，例如钓鱼（T1566）、搜索开放技术数据库（T1596）、建立运营资源（T1583/T1584）或通过有效账户（T1078）或钓鱼实现初始访问。

## 测试案例
以下是模拟攻击者使用搜索引擎收集信息的常见方法和工具：

### 1. **Google Hacking 基础**
利用Google高级搜索语法查找目标的敏感信息：
- **intitle**：搜索网页标题中的关键词。
  ```bash
  intitle:"admin login" site:target.com
  # 查找目标网站标题中包含“admin login”的页面
  ```
- **inurl**：搜索URL中的关键词。
  ```bash
  inurl:(admin | login) site:target.com
  # 查找目标网站URL中包含“admin”或“login”的页面
  ```
- **intext**：搜索网页正文中的关键词。
  ```bash
  intext:(password | admin) site:target.com
  # 查找网页正文包含“password”或“admin”的页面
  ```
- **filetype**：搜索特定类型的文件。
  ```bash
  filetype:pdf site:target.com "staff directory"
  # 查找目标网站上的员工目录PDF
  ```
- **site**：限制搜索范围到特定网站。
  ```bash
  site:*.target.com -inurl:(signup | login)
  # 查找目标网站的所有子域名，排除注册或登录页面
  ```
- **allinurl**：搜索URL中包含多个关键词。
  ```bash
  allinurl:(manage system) site:target.com
  # 查找URL同时包含“manage”和“system”的页面
  ```

### 2. **Google Hacking 进阶**
- **查找后台地址**：
  ```bash
  site:target.com inurl:(login | admin | manage | member | admin_login | login_admin | system | user | main | cms)
  # 查找可能的后台登录页面
  ```
- **查找泄露凭据**：
  ```bash
  site:*.target.com intext:(admin | username | password | system | login)
  # 查找包含敏感信息的页面
  ```
- **查找可注入点**：
  ```bash
  site:target.com inurl:(aspx | jsp | php | asp)
  # 查找可能存在SQL注入或XSS漏洞的动态页面
  ```
- **查找上传漏洞**：
  ```bash
  site:target.com inurl:(file | load | editor | Files)
  # 查找文件上传页面
  ```
- **查找网络设备**：
  ```bash
  intext:"WEB Management Interface" site:target.com
  # 查找暴露的网络设备管理界面
  ```
- **查找数据库文件**：
  ```bash
  site:target.com filetype:(mdb | sql | bak)
  # 查找暴露的数据库备份文件
  ```

### 3. **其他搜索引擎**
- **百度**：使用类似Google Hacking的语法，适合国内目标。
  ```bash
  site:target.com 后台管理
  # 查找包含“后台管理”的页面
  ```
- **Bing**：支持`inurl`、`site`等语法。
  ```bash
  site:target.com inurl:login
  # 查找登录页面
  ```
- **Shodan Search** (<https://www.shodan.io>): 结合搜索引擎查询网络设备。
  ```bash
  org:TargetCorp port:80
  # 查找目标组织的Web服务器
  ```

### 4. **案例场景**
- 使用Google搜索`site:target.com filetype:pdf "employee list"`，发现员工名单PDF，提取邮箱用于钓鱼。
- 使用`site:target.com inurl:admin`找到未受保护的后台登录页面，尝试默认凭据登录。
- 参考案例：<https://cloud.tencent.com/developer/article/1752139>，通过Google Hacking发现目标网站的敏感配置文件。

## 检测日志
搜索引擎信息收集多通过公开渠道进行，难以直接监测。以下是可能的日志来源：
- **Web服务器日志**：
  - 记录异常的HTTP请求，如高频爬取、异常User-Agent或Referer。
- **WAF日志**：
  - 检测被WAF拦截的爬虫请求或异常搜索模式。
- **DNS日志**：
  - 检测针对子域名的异常查询，可能与搜索引擎发现的子域名相关。
- **邮件服务器日志**：
  - 监控钓鱼邮件或社会工程攻击，可能与搜索到的邮箱信息相关。

## 测试复现
以下是模拟搜索引擎信息收集的步骤：
1. **环境准备**：
   - 在授权测试环境中搭建目标网站，包含公开页面、PDF文档或子域名。
2. **搜索执行**：
   - 使用Google搜索：
     ```bash
     site:target.com inurl:admin
     site:target.com filetype:pdf "contact"
     ```
   - 使用百度搜索：
     ```bash
     site:target.com 管理后台
     ```
   - 使用Shodan查询：
     ```bash
     org:TargetCorp port:443
     ```
3. **爬虫模拟**：
   - 使用Scrapy爬取目标网站：
     ```python
     import scrapy
     class TargetSpider(scrapy.Spider):
         name = "target_spider"
         start_urls = ["http://www.target.com"]
         def parse(self, response):
             emails = response.xpath("//a[contains(@href, 'mailto:')]/text()").getall()
             yield {"emails": emails}
     ```
   - 运行：`scrapy crawl target_spider -o emails.json`
4. **结果分析**：
   - 整理收集到的邮箱、子域名或敏感文件，分析潜在攻击入口。
5. **日志收集**：
   - 收集Web服务器、WAF和DNS日志，验证爬虫或搜索痕迹。

## 测试留痕
搜索引擎信息收集可能留下以下痕迹：
- **Web服务器日志**：高频HTTP请求、异常User-Agent（如`Googlebot`、`python-requests`）或爬虫模式（如访问robots.txt）。
- **WAF/IDS告警**：触发爬虫检测规则或高频请求限制。
- **DNS日志**：子域名枚举导致的异常DNS查询。
- **邮件服务器日志**：钓鱼邮件或社会工程交互记录。

## 检测规则/思路
由于搜索引擎信息收集多发生在目标组织监测范围之外，检测需结合多种手段：
- **Web流量监控**：
  - 使用WAF（如Cloudflare、ModSecurity）检测异常爬虫行为，匹配常见User-Agent（如`Googlebot`、`Scrapy`）。
  - 示例WAF规则：
    ```nginx
    if ($http_user_agent ~* "(Scrapy|python-requests|bot)") {
        return 403;
    }
    ```
  - 监控高频HTTP请求或异常路径访问（如`/admin`、`.pdf`）。
- **DNS查询监控**：
  - 记录针对子域名的异常DNS查询，检测可能的子域名发现行为。
  - 使用DNS防火墙（如Cloudflare Gateway）阻止已知的恶意查询来源。
- **信息泄露防护**：
  - 使用DLP（数据丢失防护）工具，检测员工通过邮件或社交媒体泄露敏感信息。
  - 监控公开信息源（如Pastebin、暗网论坛）中是否出现组织的敏感数据。
- **威胁情报整合**：
  - 结合威胁情报平台（如微步在线、奇安信），识别已知的爬虫IP或钓鱼模式。
  - 使用Google Alerts监控与组织相关的公开信息泄露。

## 建议
- **减少信息暴露**：
  - 限制网站上公开的敏感信息（如员工邮箱、PDF文档）。
  - 使用robots.txt限制搜索引擎爬取敏感页面（如`/admin`）。
  - 定期检查搜索引擎缓存（如Google Cache）或存档网站（如Wayback Machine），请求删除泄露信息。
- **网站安全加固**：
  - 配置WAF保护网站，拦截异常爬虫或高频请求。
  - 实施MFA（多因素认证）保护后台登录页面。
  - 定期审计子域名，移除不必要的或未受保护的子域名。
- **主动监控与响应**：
  - 使用Google Alerts或类似工具监控与组织相关的公开信息。
  - 部署Web日志分析工具（如Splunk、ELK），监控异常爬取行为。
  - 使用威胁狩猎（Threat Hunting）技术，主动搜索可能的搜索引擎侦察活动。
- **后续阶段检测**：
  - 重点监控攻击者生命周期的后续阶段（如初始访问T1566、有效账户T1078），通过异常流量或钓鱼行为间接发现侦察活动。

## 参考资料
- MITRE ATT&CK: T1593-002  
  <https://attack.mitre.org/techniques/T1593/002/>
- Github Hacking | Google Hacking - 信息搜集篇  
  <https://cloud.tencent.com/developer/article/1752139>
- Google Hacking 总结  
  <https://www.jianshu.com/p/f8062e2cc1d7>
- 信息收集之 Google Hacking 的简单用法  
  <https://blog.csdn.net/qq_36119192/article/details/84029809>